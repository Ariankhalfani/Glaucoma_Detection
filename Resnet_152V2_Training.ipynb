{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tvhsNfjlXpJX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ulODETq6YcyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8030dfee-9a21-4858-f94a-d7beeb19cd26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "kiXy4s7sXxJl"
      },
      "outputs": [],
      "source": [
        "def load_glaucoma_dataset(data_dir, image_size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = ['Glaucoma_Positive', 'Glaucoma_Negative']\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        class_label = class_names.index(class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.resize(img, (image_size, image_size))\n",
        "                img = img / 255.0\n",
        "                images.append(img)\n",
        "                labels.append(class_label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "your_dataset_path = r\"/content/drive/MyDrive/Dataset_Sardjito\"\n",
        "your_image_size = 224  # Change this to the size required by ResNet152V2\n",
        "\n",
        "glaucoma_train_images, glaucoma_train_labels = load_glaucoma_dataset(os.path.join(your_dataset_path, 'train'), your_image_size)\n",
        "glaucoma_test_images, glaucoma_test_labels = load_glaucoma_dataset(os.path.join(your_dataset_path, 'test'), your_image_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo56Q6fhJ_2T",
        "outputId": "a91387e1-4973-41dc-859c-f056ef20e437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import ResNet152V2\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define your image size\n",
        "your_image_size = 224  # Replace with your desired image size\n",
        "\n",
        "# Load ResNetV2-152 pre-trained on ImageNet without the top classification layer\n",
        "base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=(your_image_size, your_image_size, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create the model by adding custom layers on top of the pre-trained ResNetV2-152\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(2048, activation='relu'),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "43XxZWryxKOT",
        "outputId": "29f4b2b6-b3cc-4dfa-d8df-8ba84c530e89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 60s 10s/step - loss: 2.1211 - accuracy: 0.7600 - val_loss: 0.6106 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 25s 5s/step - loss: 0.4989 - accuracy: 0.7943 - val_loss: 0.4403 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 30s 6s/step - loss: 0.3941 - accuracy: 0.8286 - val_loss: 0.3360 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.3139 - accuracy: 0.8571"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-36da12160330>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Use all callbacks in the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m history = model.fit(glaucoma_train_images, glaucoma_train_labels,\n\u001b[0m\u001b[1;32m     19\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1872\u001b[0m                     \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m                 \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-36da12160330>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(epoch, logs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Custom callback to save the best model at the end of training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mbest_model_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambdaCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Dataset_Latihan/best_model.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Use all callbacks in the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m   3101\u001b[0m         \u001b[0mNote\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0man\u001b[0m \u001b[0malias\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m         \"\"\"\n\u001b[0;32m-> 3103\u001b[0;31m         saving_api.save_model(\n\u001b[0m\u001b[1;32m   3104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# Legacy case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         return legacy_sm_saving_lib.save_model(\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;34m'setting save_format=\"tf\") or using `save_weights`.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             )\n\u001b[0;32m--> 160\u001b[0;31m         hdf5_format.save_model_to_hdf5(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         ):\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0msave_optimizer_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/hdf5_format.py\u001b[0m in \u001b[0;36msave_optimizer_weights_to_hdf5_group\u001b[0;34m(hdf5_group, optimizer)\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0mparam_dset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                 \u001b[0mparam_dset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LambdaCallback\n",
        "import tensorflow as tf\n",
        "\n",
        "# Assuming your model is already defined and created here\n",
        "\n",
        "# Compile the model before training\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create the ModelCheckpoint callback with a dummy filepath\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=200, verbose=0, mode='min', restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/Dataset_Latihan/dummy_model.h5\", monitor='val_loss',  mode='min', save_best_only=True, save_weights_only=False)\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "# Custom callback to save the best model at the end of training\n",
        "best_model_saver = LambdaCallback(on_epoch_end=lambda epoch, logs: model.save(\"/content/drive/MyDrive/Dataset_Latihan/best_model.h5\", save_format=\"h5\"))\n",
        "\n",
        "# Use all callbacks in the training loop\n",
        "history = model.fit(glaucoma_train_images, glaucoma_train_labels,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(glaucoma_test_images, glaucoma_test_labels),\n",
        "                    callbacks=[checkpoint, early_stopping, reduce_lr_loss, best_model_saver])\n",
        "\n",
        "# Save the final model in the native Keras format\n",
        "model.save(\"/content/drive/MyDrive/Dataset_Latihan/Try_model.h5\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def load_glaucoma_dataset_generator(dataset_path, image_size, batch_size=32):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',  # Assuming it's a binary classification task\n",
        "        shuffle=True  # Set to True if you want to shuffle the order of the images\n",
        "    )\n",
        "\n",
        "    # Retrieve the total number of samples\n",
        "    num_samples = generator.samples\n",
        "\n",
        "    return generator, num_samples\n",
        "\n",
        "# Example usage:\n",
        "your_dataset_path = r\"/content/drive/MyDrive/Dataset_LAG\"\n",
        "your_image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "# Define the path to the training dataset\n",
        "train_dataset_path = os.path.join(your_dataset_path, 'train')\n",
        "\n",
        "# Create a generator for the training dataset\n",
        "train_generator, num_train_samples = load_glaucoma_dataset_generator(train_dataset_path, your_image_size, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyN90ri-0whs",
        "outputId": "c820f48c-aa18-4aa1-90e2-45a624ebae0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4409 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LambdaCallback\n",
        "\n",
        "# Load glaucoma dataset using a generator\n",
        "def load_glaucoma_dataset_generator(dataset_path, image_size, batch_size=32):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',  # Assuming it's a binary classification task\n",
        "        shuffle=True  # Set to True if you want to shuffle the order of the images\n",
        "    )\n",
        "\n",
        "    # Retrieve the total number of samples\n",
        "    num_samples = generator.samples\n",
        "\n",
        "    return generator, num_samples\n",
        "\n",
        "# Example usage:\n",
        "your_dataset_path = r\"/content/drive/MyDrive/Dataset_Sardjito\"\n",
        "your_image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "# Define the path to the training dataset\n",
        "train_dataset_path = os.path.join(your_dataset_path, 'train')\n",
        "\n",
        "# Create a generator for the training dataset\n",
        "train_generator, num_train_samples = load_glaucoma_dataset_generator(train_dataset_path, your_image_size, batch_size)\n",
        "\n",
        "# Define the path to the testing dataset\n",
        "test_dataset_path = os.path.join(your_dataset_path, 'test')\n",
        "\n",
        "# Create a generator for the testing dataset\n",
        "test_generator, num_test_samples = load_glaucoma_dataset_generator(test_dataset_path, your_image_size, batch_size)\n",
        "\n",
        "# Assuming your model is already defined and created here\n",
        "\n",
        "# Compile the model before training\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create the ModelCheckpoint callback with a dummy filepath\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min', restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/Dataset_Latihan/dummy_model.h5\", monitor='val_loss', mode='min', save_best_only=True, save_weights_only=False)\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=50, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "# Custom callback to save the best model at the end of training\n",
        "best_model_saver = LambdaCallback(on_epoch_end=lambda epoch, logs: model.save(\"/content/drive/MyDrive/Dataset_Latihan/best_model.h5\", save_format=\"h5\"))\n",
        "\n",
        "# Use all callbacks in the training loop\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=num_train_samples // batch_size,\n",
        "    epochs=50,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=num_test_samples // batch_size,\n",
        "    callbacks=[checkpoint, early_stopping, reduce_lr_loss, best_model_saver]\n",
        ")\n",
        "\n",
        "# Save the final model in the native Keras format\n",
        "model.save(\"/content/drive/MyDrive/Dataset_Latihan/Try_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHDdssBC4OyB",
        "outputId": "245085e1-437b-4f49-f6df-ae006e1130ca"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 175 images belonging to 2 classes.\n",
            "Found 10 images belonging to 2 classes.\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 50s 10s/step - loss: 1.3480 - accuracy: 0.6224 - val_loss: 2.5908 - val_accuracy: 0.2000 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 58s 14s/step - loss: 0.5690 - accuracy: 0.8188 - val_loss: 1.2246 - val_accuracy: 0.2000 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.4969 - accuracy: 0.8182 - val_loss: 1.2835 - val_accuracy: 0.2000 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 21s 5s/step - loss: 0.4469 - accuracy: 0.8313 - val_loss: 1.9121 - val_accuracy: 0.2000 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 17s 4s/step - loss: 0.4127 - accuracy: 0.8112 - val_loss: 1.3673 - val_accuracy: 0.2000 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 21s 5s/step - loss: 0.3275 - accuracy: 0.8671 - val_loss: 1.9679 - val_accuracy: 0.2000 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 19s 4s/step - loss: 0.3136 - accuracy: 0.8392 - val_loss: 1.8711 - val_accuracy: 0.1000 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_glaucoma_dataset_generator(dataset_path, image_size, batch_size=32):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',  # Assuming it's a binary classification task\n",
        "        shuffle=False  # Ensure that the order is preserved\n",
        "    )\n",
        "\n",
        "    # Retrieve the total number of samples\n",
        "    num_samples = generator.samples\n",
        "\n",
        "    return generator, num_samples\n",
        "\n",
        "# Example usage:\n",
        "your_dataset_path = r\"/content/drive/MyDrive/Dataset_Latihan\"\n",
        "your_image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "# Define the path to the test dataset\n",
        "test_dataset_path = os.path.join(your_dataset_path, 'test')\n",
        "\n",
        "# Create a generator for the test dataset\n",
        "test_generator, num_test_samples = load_glaucoma_dataset_generator(test_dataset_path, your_image_size, batch_size)\n",
        "\n",
        "# Define the path to your pre-trained model\n",
        "model_path = \"/content/drive/MyDrive/Dataset_Latihan/dummy_model.h5\"  # Change this to the path of your saved model\n",
        "\n",
        "# Load the pre-trained model\n",
        "loaded_model = load_model(model_path)\n",
        "\n",
        "# Initialize variables for confusion matrix\n",
        "all_true_labels = []\n",
        "all_predicted_labels = []\n",
        "\n",
        "# Calculate the total number of batches\n",
        "total_batches = num_test_samples // batch_size\n",
        "\n",
        "# Iterate over batches\n",
        "for i in range(total_batches + 1):  # +1 to include the last batch\n",
        "    batch_images, batch_labels = test_generator.next()\n",
        "\n",
        "    # Perform predictions on the batch\n",
        "    predictions = loaded_model.predict(batch_images)\n",
        "    predicted_labels = np.round(predictions).flatten()\n",
        "\n",
        "    # Append true and predicted labels for confusion matrix\n",
        "    all_true_labels.extend(batch_labels)\n",
        "    all_predicted_labels.extend(predicted_labels)\n",
        "\n",
        "    # Calculate loading and prediction process\n",
        "    process_percentage = (i + 1) / (total_batches + 1) * 100\n",
        "    print(f\"Processing: {process_percentage:.2f}%\")\n",
        "\n",
        "# Convert true and predicted labels to numpy arrays\n",
        "all_true_labels = np.array(all_true_labels)\n",
        "all_predicted_labels = np.array(all_predicted_labels)\n",
        "\n",
        "# Evaluate the model on the entire test set\n",
        "test_loss, test_accuracy = loaded_model.evaluate(test_generator)\n",
        "\n",
        "# Print test accuracy, test loss, confusion matrix, and classification report\n",
        "print(f\"\\nTest Accuracy: {test_accuracy}\")\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "class_report = classification_report(all_true_labels, all_predicted_labels)\n",
        "print(class_report)\n",
        "\n",
        "# Save the confusion matrix\n",
        "conf_matrix_save_path = \"/content/drive/MyDrive/confusion_matrix.npy\"\n",
        "np.save(conf_matrix_save_path, conf_matrix)\n",
        "print(f\"\\nConfusion Matrix saved at: {conf_matrix_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wKbqKySEVB9",
        "outputId": "f38f78a2-f9c2-4638-d638-11c7451d30fa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 224 images belonging to 2 classes.\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Processing: 12.50%\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Processing: 25.00%\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "Processing: 37.50%\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Processing: 50.00%\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Processing: 62.50%\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Processing: 75.00%\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Processing: 87.50%\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Processing: 100.00%\n",
            "7/7 [==============================] - 10s 1s/step - loss: 1.4491 - accuracy: 0.7411\n",
            "\n",
            "Test Accuracy: 0.7410714030265808\n",
            "Test Loss: 1.4490729570388794\n",
            "\n",
            "Confusion Matrix:\n",
            "[[180  22]\n",
            " [ 40  14]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.89      0.85       202\n",
            "         1.0       0.39      0.26      0.31        54\n",
            "\n",
            "    accuracy                           0.76       256\n",
            "   macro avg       0.60      0.58      0.58       256\n",
            "weighted avg       0.73      0.76      0.74       256\n",
            "\n",
            "\n",
            "Confusion Matrix saved at: /content/drive/MyDrive/confusion_matrix.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_glaucoma_dataset_generator(dataset_path, image_size, batch_size=32):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',  # Assuming it's a binary classification task\n",
        "        shuffle=False  # Ensure that the order is preserved\n",
        "    )\n",
        "\n",
        "    # Retrieve the total number of samples\n",
        "    num_samples = generator.samples\n",
        "\n",
        "    return generator, num_samples\n",
        "\n",
        "# Example usage:\n",
        "your_dataset_path = r\"/content/drive/MyDrive/Dataset_LAG\"\n",
        "your_image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "# Define the path to the test dataset\n",
        "test_dataset_path = os.path.join(your_dataset_path, 'test')\n",
        "\n",
        "# Create a generator for the test dataset\n",
        "test_generator, num_test_samples = load_glaucoma_dataset_generator(test_dataset_path, your_image_size, batch_size)\n",
        "\n",
        "# Define the path to your pre-trained model\n",
        "model_path = \"/content/drive/MyDrive/Dataset_Latihan/dummy_model.h5\"  # Change this to the path of your saved model\n",
        "\n",
        "# Load the pre-trained model\n",
        "loaded_model = load_model(model_path)\n",
        "\n",
        "# Initialize variables for confusion matrix\n",
        "all_true_labels = []\n",
        "all_predicted_labels = []\n",
        "\n",
        "# Calculate the total number of batches\n",
        "total_batches = num_test_samples // batch_size\n",
        "\n",
        "# Iterate over batches\n",
        "for i in range(total_batches + 1):  # +1 to include the last batch\n",
        "    batch_images, batch_labels = test_generator.next()\n",
        "\n",
        "    # Perform predictions on the batch\n",
        "    predictions = loaded_model.predict(batch_images)\n",
        "    predicted_labels = np.round(predictions).flatten()\n",
        "\n",
        "    # Append true and predicted labels for confusion matrix\n",
        "    all_true_labels.extend(batch_labels)\n",
        "    all_predicted_labels.extend(predicted_labels)\n",
        "\n",
        "    # Calculate loading and prediction process\n",
        "    process_percentage = (i + 1) / (total_batches + 1) * 100\n",
        "    print(f\"Processing: {process_percentage:.2f}%\")\n",
        "\n",
        "# Convert true and predicted labels to numpy arrays\n",
        "all_true_labels = np.array(all_true_labels)\n",
        "all_predicted_labels = np.array(all_predicted_labels)\n",
        "\n",
        "# Evaluate the model on the entire test set\n",
        "test_loss, test_accuracy = loaded_model.evaluate(test_generator)\n",
        "\n",
        "# Print test accuracy, test loss, confusion matrix, and classification report\n",
        "print(f\"\\nTest Accuracy: {test_accuracy}\")\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "class_report = classification_report(all_true_labels, all_predicted_labels)\n",
        "print(class_report)\n",
        "\n",
        "# Save the confusion matrix\n",
        "conf_matrix_save_path = \"/content/drive/MyDrive/confusion_matrix.npy\"\n",
        "np.save(conf_matrix_save_path, conf_matrix)\n",
        "print(f\"\\nConfusion Matrix saved at: {conf_matrix_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dWfILezFAz3",
        "outputId": "096b2bcd-5a4c-49b2-bc70-bdb82add1882"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 243 images belonging to 2 classes.\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Processing: 12.50%\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Processing: 25.00%\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Processing: 37.50%\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Processing: 50.00%\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Processing: 62.50%\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Processing: 75.00%\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Processing: 87.50%\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Processing: 100.00%\n",
            "8/8 [==============================] - 5s 225ms/step - loss: 1.5239 - accuracy: 0.6708\n",
            "\n",
            "Test Accuracy: 0.6707819104194641\n",
            "Test Loss: 1.523909091949463\n",
            "\n",
            "Confusion Matrix:\n",
            "[[155   2]\n",
            " [ 78   8]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.99      0.79       157\n",
            "         1.0       0.80      0.09      0.17        86\n",
            "\n",
            "    accuracy                           0.67       243\n",
            "   macro avg       0.73      0.54      0.48       243\n",
            "weighted avg       0.71      0.67      0.57       243\n",
            "\n",
            "\n",
            "Confusion Matrix saved at: /content/drive/MyDrive/confusion_matrix.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_glaucoma_dataset_generator(dataset_path, image_size, batch_size=32):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',  # Assuming it's a binary classification task\n",
        "        shuffle=False  # Ensure that the order is preserved\n",
        "    )\n",
        "\n",
        "    # Retrieve the total number of samples\n",
        "    num_samples = generator.samples\n",
        "\n",
        "    return generator, num_samples\n",
        "\n",
        "# Example usage:\n",
        "your_dataset_path = r\"/content/drive/MyDrive/Dataset_Latihan\"\n",
        "your_image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "# Define the path to the test dataset\n",
        "test_dataset_path = os.path.join(your_dataset_path, 'test')\n",
        "\n",
        "# Create a generator for the test dataset\n",
        "test_generator, num_test_samples = load_glaucoma_dataset_generator(test_dataset_path, your_image_size, batch_size)\n",
        "\n",
        "# Define the path to your pre-trained model\n",
        "model_path = \"/content/drive/MyDrive/dummy_model.h5\"  # Change this to the path of your saved model\n",
        "\n",
        "# Load the pre-trained model\n",
        "loaded_model = load_model(model_path)\n",
        "\n",
        "# Initialize variables for confusion matrix\n",
        "all_true_labels = []\n",
        "all_predicted_labels = []\n",
        "\n",
        "# Calculate the total number of batches\n",
        "total_batches = num_test_samples // batch_size\n",
        "\n",
        "# Iterate over batches\n",
        "for i in range(total_batches + 1):  # +1 to include the last batch\n",
        "    batch_images, batch_labels = test_generator.next()\n",
        "\n",
        "    # Perform predictions on the batch\n",
        "    predictions = loaded_model.predict(batch_images)\n",
        "    predicted_labels = np.round(predictions).flatten()\n",
        "\n",
        "    # Append true and predicted labels for confusion matrix\n",
        "    all_true_labels.extend(batch_labels)\n",
        "    all_predicted_labels.extend(predicted_labels)\n",
        "\n",
        "    # Calculate loading and prediction process\n",
        "    process_percentage = (i + 1) / (total_batches + 1) * 100\n",
        "    print(f\"Processing: {process_percentage:.2f}%\")\n",
        "\n",
        "# Convert true and predicted labels to numpy arrays\n",
        "all_true_labels = np.array(all_true_labels)\n",
        "all_predicted_labels = np.array(all_predicted_labels)\n",
        "\n",
        "# Evaluate the model on the entire test set\n",
        "test_loss, test_accuracy = loaded_model.evaluate(test_generator)\n",
        "\n",
        "# Print test accuracy, test loss, confusion matrix, and classification report\n",
        "print(f\"\\nTest Accuracy: {test_accuracy}\")\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "class_report = classification_report(all_true_labels, all_predicted_labels)\n",
        "print(class_report)\n",
        "\n",
        "# Save the confusion matrix\n",
        "conf_matrix_save_path = \"/content/drive/MyDrive/confusion_matrix.npy\"\n",
        "np.save(conf_matrix_save_path, conf_matrix)\n",
        "print(f\"\\nConfusion Matrix saved at: {conf_matrix_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "9dwFX_1WGIBA",
        "outputId": "fd22a292-e147-41ca-eb8f-9bbfeb88bc70"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 224 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7559d5cd571e>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Load the pre-trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Initialize variables for confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at /content/drive/MyDrive/dummy_model.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data(input_folder, output_folder, train_percent=0.9, test_percent=0.05, val_percent=0.05):\n",
        "    # Create train, test, and val folders in the output directory\n",
        "    train_folder = os.path.join(output_folder, 'train')\n",
        "    test_folder = os.path.join(output_folder, 'test')\n",
        "    val_folder = os.path.join(output_folder, 'val')\n",
        "\n",
        "    os.makedirs(train_folder, exist_ok=True)\n",
        "    os.makedirs(test_folder, exist_ok=True)\n",
        "    os.makedirs(val_folder, exist_ok=True)\n",
        "\n",
        "    for class_folder in os.listdir(input_folder):\n",
        "        input_class_folder = os.path.join(input_folder, class_folder)\n",
        "\n",
        "        if os.path.isdir(input_class_folder):\n",
        "            # Create class-specific train, test, and val folders\n",
        "            train_class_folder = os.path.join(train_folder, class_folder)\n",
        "            test_class_folder = os.path.join(test_folder, class_folder)\n",
        "            val_class_folder = os.path.join(val_folder, class_folder)\n",
        "\n",
        "            os.makedirs(train_class_folder, exist_ok=True)\n",
        "            os.makedirs(test_class_folder, exist_ok=True)\n",
        "            os.makedirs(val_class_folder, exist_ok=True)\n",
        "\n",
        "            # List all files in the input folder\n",
        "            all_files = os.listdir(input_class_folder)\n",
        "            total_files = len(all_files)\n",
        "\n",
        "            # Split files into train, test, and val sets\n",
        "            train_files, test_val_files = train_test_split(all_files, test_size=(test_percent + val_percent), random_state=42)\n",
        "            test_files, val_files = train_test_split(test_val_files, test_size=val_percent/(test_percent + val_percent), random_state=42)\n",
        "\n",
        "            # Copy files to the corresponding class-specific folders\n",
        "            for file_name in train_files:\n",
        "                shutil.copy(os.path.join(input_class_folder, file_name), os.path.join(train_class_folder, file_name))\n",
        "\n",
        "            for file_name in test_files:\n",
        "                shutil.copy(os.path.join(input_class_folder, file_name), os.path.join(test_class_folder, file_name))\n",
        "\n",
        "            for file_name in val_files:\n",
        "                shutil.copy(os.path.join(input_class_folder, file_name), os.path.join(val_class_folder, file_name))\n",
        "\n",
        "# Example usage:\n",
        "input_folder = r\"/content/drive/MyDrive/Dataset_Sardjito/Bare\"\n",
        "output_folder = r\"/content/drive/MyDrive/Dataset_Sardjito\"  # Change this to the desired output path\n",
        "\n",
        "split_data(input_folder, output_folder)"
      ],
      "metadata": {
        "id": "tGAyl475Oswe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Define the path to your pre-trained model\n",
        "model_path = r\"/content/drive/MyDrive/Dataset_Latihan/Try_model.h5\"  # Change this to the path of your saved model\n",
        "\n",
        "# Load the pre-trained model\n",
        "loaded_model = load_model(model_path)\n",
        "\n",
        "# Assuming you have loaded your test datasets: glaucoma_test_images, glaucoma_test_labels\n",
        "\n",
        "# Perform predictions on the test set\n",
        "predictions = loaded_model.predict(glaucoma_test_images)\n",
        "predicted_labels = np.round(predictions).flatten()\n",
        "\n",
        "# Convert true labels to binary (assuming it's not binary already)\n",
        "true_labels = np.array(glaucoma_test_labels).flatten()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = loaded_model.evaluate(glaucoma_test_images, glaucoma_test_labels)\n",
        "\n",
        "# Print test accuracy, test loss, confusion matrix, and classification report\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "eUSNN4DcCJ2R",
        "outputId": "8f48b061-bc55-4de9-b9ca-ce0d0b71a148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1930ecfb6779>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Perform predictions on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglaucoma_test_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'glaucoma_test_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXPbeqkFYNR5",
        "outputId": "19d300c2-d27b-49ee-ec4d-699f621cbd04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 - 1s - loss: 0.8860 - accuracy: 0.8571 - 1s/epoch - 214ms/step\n",
            "Test accuracy: 0.8571428656578064\n",
            "7/7 [==============================] - 4s 217ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77        54\n",
            "           1       1.00      0.81      0.90       170\n",
            "\n",
            "    accuracy                           0.86       224\n",
            "   macro avg       0.81      0.91      0.83       224\n",
            "weighted avg       0.91      0.86      0.87       224\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 54   0]\n",
            " [ 32 138]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(glaucoma_test_images, glaucoma_test_labels, verbose=2)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(glaucoma_test_images)\n",
        "predicted_labels = np.round(predictions).flatten()\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(glaucoma_test_labels, predicted_labels))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(glaucoma_test_labels, predicted_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zvkbs8qa8cEo"
      },
      "outputs": [],
      "source": [
        "save_path = r\"/content/drive/MyDrive/Dataset_Latihan\"  # Specify your desired save path\n",
        "model.save(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4m0PAsueSR0",
        "outputId": "2faf9772-da13-46a8-9513-7dc17e9978de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 18s 671ms/step - loss: 0.5654 - accuracy: 0.7287 - val_loss: 0.4862 - val_accuracy: 0.8125\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.5404 - accuracy: 0.7448Restoring model weights from the end of the best epoch: 1.\n",
            "14/14 [==============================] - 5s 359ms/step - loss: 0.5404 - accuracy: 0.7448 - val_loss: 0.4352 - val_accuracy: 0.8214\n",
            "Epoch 2: early stopping\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Save the model with the lowest validation loss\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', save_best_only=True, save_weights_only=False)\n",
        "\n",
        "# Stop training if the validation loss does not improve for 3 consecutive epochs\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(glaucoma_train_images, glaucoma_train_labels,\n",
        "                    epochs=20,  # Increase the number of epochs to allow early stopping to work\n",
        "                    batch_size=32,\n",
        "                    validation_data=(glaucoma_test_images, glaucoma_test_labels),\n",
        "                    callbacks=[checkpoint, early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC4NKPghgsKE",
        "outputId": "d8ea1473-068f-4bba-ac11-3296dea86ec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.9563"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 18s 617ms/step - loss: 0.1939 - accuracy: 0.9563 - val_loss: 0.3795 - val_accuracy: 0.8661\n",
            "Epoch 2/1000\n",
            "14/14 [==============================] - 6s 436ms/step - loss: 0.1860 - accuracy: 0.9586 - val_loss: 0.3383 - val_accuracy: 0.8750\n",
            "Epoch 3/1000\n",
            "14/14 [==============================] - 4s 320ms/step - loss: 0.1886 - accuracy: 0.9563 - val_loss: 0.3526 - val_accuracy: 0.8661\n",
            "Epoch 4/1000\n",
            "14/14 [==============================] - 5s 374ms/step - loss: 0.1850 - accuracy: 0.9632 - val_loss: 0.3126 - val_accuracy: 0.8839\n",
            "Epoch 5/1000\n",
            "14/14 [==============================] - 5s 401ms/step - loss: 0.1881 - accuracy: 0.9655 - val_loss: 0.3102 - val_accuracy: 0.8750\n",
            "Epoch 6/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.1891 - accuracy: 0.9425 - val_loss: 0.4182 - val_accuracy: 0.8393\n",
            "Epoch 7/1000\n",
            "14/14 [==============================] - 6s 429ms/step - loss: 0.1852 - accuracy: 0.9609 - val_loss: 0.3021 - val_accuracy: 0.8839\n",
            "Epoch 8/1000\n",
            "14/14 [==============================] - 6s 438ms/step - loss: 0.1808 - accuracy: 0.9701 - val_loss: 0.3002 - val_accuracy: 0.8839\n",
            "Epoch 9/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.1796 - accuracy: 0.9586 - val_loss: 0.3312 - val_accuracy: 0.8661\n",
            "Epoch 10/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.1755 - accuracy: 0.9701 - val_loss: 0.3472 - val_accuracy: 0.8750\n",
            "Epoch 11/1000\n",
            "14/14 [==============================] - 4s 307ms/step - loss: 0.1761 - accuracy: 0.9563 - val_loss: 0.3417 - val_accuracy: 0.8661\n",
            "Epoch 12/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.1731 - accuracy: 0.9609 - val_loss: 0.3462 - val_accuracy: 0.8839\n",
            "Epoch 13/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.1722 - accuracy: 0.9678 - val_loss: 0.3310 - val_accuracy: 0.8750\n",
            "Epoch 14/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.1697 - accuracy: 0.9655 - val_loss: 0.3545 - val_accuracy: 0.8750\n",
            "Epoch 15/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.1682 - accuracy: 0.9770 - val_loss: 0.3070 - val_accuracy: 0.8839\n",
            "Epoch 16/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.1677 - accuracy: 0.9701 - val_loss: 0.3236 - val_accuracy: 0.8750\n",
            "Epoch 17/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.1658 - accuracy: 0.9678 - val_loss: 0.3525 - val_accuracy: 0.8750\n",
            "Epoch 18/1000\n",
            "14/14 [==============================] - 4s 326ms/step - loss: 0.1688 - accuracy: 0.9701 - val_loss: 0.3260 - val_accuracy: 0.8750\n",
            "Epoch 19/1000\n",
            "14/14 [==============================] - 5s 378ms/step - loss: 0.1684 - accuracy: 0.9816 - val_loss: 0.2865 - val_accuracy: 0.8929\n",
            "Epoch 20/1000\n",
            "14/14 [==============================] - 4s 289ms/step - loss: 0.1629 - accuracy: 0.9701 - val_loss: 0.3503 - val_accuracy: 0.8750\n",
            "Epoch 21/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.1618 - accuracy: 0.9701 - val_loss: 0.3110 - val_accuracy: 0.8750\n",
            "Epoch 22/1000\n",
            "14/14 [==============================] - 4s 324ms/step - loss: 0.1603 - accuracy: 0.9770 - val_loss: 0.3307 - val_accuracy: 0.8839\n",
            "Epoch 23/1000\n",
            "14/14 [==============================] - 4s 324ms/step - loss: 0.1595 - accuracy: 0.9793 - val_loss: 0.3039 - val_accuracy: 0.8839\n",
            "Epoch 24/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.1591 - accuracy: 0.9701 - val_loss: 0.3687 - val_accuracy: 0.8750\n",
            "Epoch 25/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.1589 - accuracy: 0.9724 - val_loss: 0.3165 - val_accuracy: 0.8839\n",
            "Epoch 26/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.1577 - accuracy: 0.9839 - val_loss: 0.2865 - val_accuracy: 0.9018\n",
            "Epoch 27/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.1599 - accuracy: 0.9701 - val_loss: 0.3911 - val_accuracy: 0.8661\n",
            "Epoch 28/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.1545 - accuracy: 0.9724 - val_loss: 0.3074 - val_accuracy: 0.8750\n",
            "Epoch 29/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.1522 - accuracy: 0.9816 - val_loss: 0.3279 - val_accuracy: 0.8929\n",
            "Epoch 30/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.1525 - accuracy: 0.9793 - val_loss: 0.3228 - val_accuracy: 0.8839\n",
            "Epoch 31/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.1504 - accuracy: 0.9816 - val_loss: 0.2998 - val_accuracy: 0.8929\n",
            "Epoch 32/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.1516 - accuracy: 0.9770 - val_loss: 0.3318 - val_accuracy: 0.8929\n",
            "Epoch 33/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.1485 - accuracy: 0.9793 - val_loss: 0.3072 - val_accuracy: 0.8750\n",
            "Epoch 34/1000\n",
            "14/14 [==============================] - 4s 303ms/step - loss: 0.1470 - accuracy: 0.9793 - val_loss: 0.3407 - val_accuracy: 0.8929\n",
            "Epoch 35/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.1459 - accuracy: 0.9862 - val_loss: 0.3040 - val_accuracy: 0.8750\n",
            "Epoch 36/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.1460 - accuracy: 0.9839 - val_loss: 0.3194 - val_accuracy: 0.8929\n",
            "Epoch 37/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.1447 - accuracy: 0.9839 - val_loss: 0.3197 - val_accuracy: 0.8929\n",
            "Epoch 38/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.1437 - accuracy: 0.9816 - val_loss: 0.3324 - val_accuracy: 0.9018\n",
            "Epoch 39/1000\n",
            "14/14 [==============================] - 4s 326ms/step - loss: 0.1436 - accuracy: 0.9816 - val_loss: 0.3078 - val_accuracy: 0.8839\n",
            "Epoch 40/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.1413 - accuracy: 0.9839 - val_loss: 0.3124 - val_accuracy: 0.8929\n",
            "Epoch 41/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.1449 - accuracy: 0.9747 - val_loss: 0.3140 - val_accuracy: 0.8929\n",
            "Epoch 42/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.1399 - accuracy: 0.9770 - val_loss: 0.3425 - val_accuracy: 0.8929\n",
            "Epoch 43/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.1399 - accuracy: 0.9862 - val_loss: 0.3288 - val_accuracy: 0.8929\n",
            "Epoch 44/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.1392 - accuracy: 0.9839 - val_loss: 0.2927 - val_accuracy: 0.8929\n",
            "Epoch 45/1000\n",
            "14/14 [==============================] - 6s 420ms/step - loss: 0.1421 - accuracy: 0.9862 - val_loss: 0.2835 - val_accuracy: 0.8929\n",
            "Epoch 46/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.1376 - accuracy: 0.9793 - val_loss: 0.3860 - val_accuracy: 0.8571\n",
            "Epoch 47/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.1370 - accuracy: 0.9816 - val_loss: 0.3143 - val_accuracy: 0.8929\n",
            "Epoch 48/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.1332 - accuracy: 0.9839 - val_loss: 0.3327 - val_accuracy: 0.9018\n",
            "Epoch 49/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.1333 - accuracy: 0.9839 - val_loss: 0.3328 - val_accuracy: 0.9018\n",
            "Epoch 50/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.1329 - accuracy: 0.9862 - val_loss: 0.3064 - val_accuracy: 0.8839\n",
            "Epoch 51/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.1338 - accuracy: 0.9862 - val_loss: 0.2982 - val_accuracy: 0.8929\n",
            "Epoch 52/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.1326 - accuracy: 0.9816 - val_loss: 0.3009 - val_accuracy: 0.8929\n",
            "Epoch 53/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.1292 - accuracy: 0.9908 - val_loss: 0.3208 - val_accuracy: 0.9018\n",
            "Epoch 54/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.1307 - accuracy: 0.9885 - val_loss: 0.2979 - val_accuracy: 0.9018\n",
            "Epoch 55/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.1339 - accuracy: 0.9862 - val_loss: 0.3236 - val_accuracy: 0.9018\n",
            "Epoch 56/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.1275 - accuracy: 0.9862 - val_loss: 0.3531 - val_accuracy: 0.8839\n",
            "Epoch 57/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.1305 - accuracy: 0.9816 - val_loss: 0.3518 - val_accuracy: 0.8839\n",
            "Epoch 58/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.1411 - accuracy: 0.9770 - val_loss: 0.3051 - val_accuracy: 0.9018\n",
            "Epoch 59/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.1322 - accuracy: 0.9839 - val_loss: 0.2849 - val_accuracy: 0.8929\n",
            "Epoch 60/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.1253 - accuracy: 0.9839 - val_loss: 0.3350 - val_accuracy: 0.9018\n",
            "Epoch 61/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.1236 - accuracy: 0.9862 - val_loss: 0.3268 - val_accuracy: 0.9018\n",
            "Epoch 62/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.1232 - accuracy: 0.9885 - val_loss: 0.3332 - val_accuracy: 0.9018\n",
            "Epoch 63/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.1226 - accuracy: 0.9839 - val_loss: 0.3630 - val_accuracy: 0.8839\n",
            "Epoch 64/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.1255 - accuracy: 0.9862 - val_loss: 0.3507 - val_accuracy: 0.8839\n",
            "Epoch 65/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.1198 - accuracy: 0.9862 - val_loss: 0.3247 - val_accuracy: 0.9018\n",
            "Epoch 66/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.1194 - accuracy: 0.9908 - val_loss: 0.3572 - val_accuracy: 0.8839\n",
            "Epoch 67/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.1248 - accuracy: 0.9839 - val_loss: 0.3418 - val_accuracy: 0.8929\n",
            "Epoch 68/1000\n",
            "14/14 [==============================] - 5s 389ms/step - loss: 0.1205 - accuracy: 0.9885 - val_loss: 0.2778 - val_accuracy: 0.8929\n",
            "Epoch 69/1000\n",
            "14/14 [==============================] - 4s 326ms/step - loss: 0.1281 - accuracy: 0.9816 - val_loss: 0.3050 - val_accuracy: 0.9018\n",
            "Epoch 70/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.1195 - accuracy: 0.9747 - val_loss: 0.3765 - val_accuracy: 0.8661\n",
            "Epoch 71/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.1162 - accuracy: 0.9908 - val_loss: 0.2952 - val_accuracy: 0.9107\n",
            "Epoch 72/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.1170 - accuracy: 0.9862 - val_loss: 0.3280 - val_accuracy: 0.9018\n",
            "Epoch 73/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.1136 - accuracy: 0.9885 - val_loss: 0.3178 - val_accuracy: 0.9018\n",
            "Epoch 74/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.1131 - accuracy: 0.9931 - val_loss: 0.3150 - val_accuracy: 0.9018\n",
            "Epoch 75/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.1139 - accuracy: 0.9885 - val_loss: 0.3615 - val_accuracy: 0.8839\n",
            "Epoch 76/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.1148 - accuracy: 0.9885 - val_loss: 0.3491 - val_accuracy: 0.8839\n",
            "Epoch 77/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.1113 - accuracy: 0.9885 - val_loss: 0.3176 - val_accuracy: 0.9018\n",
            "Epoch 78/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.1102 - accuracy: 0.9885 - val_loss: 0.3430 - val_accuracy: 0.8929\n",
            "Epoch 79/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.1098 - accuracy: 0.9908 - val_loss: 0.3179 - val_accuracy: 0.9018\n",
            "Epoch 80/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.1106 - accuracy: 0.9931 - val_loss: 0.3232 - val_accuracy: 0.9018\n",
            "Epoch 81/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.1087 - accuracy: 0.9908 - val_loss: 0.3018 - val_accuracy: 0.9107\n",
            "Epoch 82/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.1104 - accuracy: 0.9862 - val_loss: 0.3744 - val_accuracy: 0.8661\n",
            "Epoch 83/1000\n",
            "14/14 [==============================] - 4s 305ms/step - loss: 0.1087 - accuracy: 0.9885 - val_loss: 0.3043 - val_accuracy: 0.9018\n",
            "Epoch 84/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.1078 - accuracy: 0.9908 - val_loss: 0.3424 - val_accuracy: 0.8929\n",
            "Epoch 85/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.1090 - accuracy: 0.9839 - val_loss: 0.3833 - val_accuracy: 0.8661\n",
            "Epoch 86/1000\n",
            "14/14 [==============================] - 4s 326ms/step - loss: 0.1130 - accuracy: 0.9862 - val_loss: 0.2980 - val_accuracy: 0.9107\n",
            "Epoch 87/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.1068 - accuracy: 0.9931 - val_loss: 0.2988 - val_accuracy: 0.9107\n",
            "Epoch 88/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.1042 - accuracy: 0.9908 - val_loss: 0.3483 - val_accuracy: 0.8839\n",
            "Epoch 89/1000\n",
            "14/14 [==============================] - 4s 326ms/step - loss: 0.1064 - accuracy: 0.9908 - val_loss: 0.3008 - val_accuracy: 0.9107\n",
            "Epoch 90/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.1030 - accuracy: 0.9931 - val_loss: 0.3336 - val_accuracy: 0.9018\n",
            "Epoch 91/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.1026 - accuracy: 0.9908 - val_loss: 0.3261 - val_accuracy: 0.9018\n",
            "Epoch 92/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.1027 - accuracy: 0.9931 - val_loss: 0.2891 - val_accuracy: 0.9196\n",
            "Epoch 93/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.1020 - accuracy: 0.9931 - val_loss: 0.3547 - val_accuracy: 0.8839\n",
            "Epoch 94/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.1025 - accuracy: 0.9908 - val_loss: 0.3338 - val_accuracy: 0.9018\n",
            "Epoch 95/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.1008 - accuracy: 0.9931 - val_loss: 0.3416 - val_accuracy: 0.9018\n",
            "Epoch 96/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.1002 - accuracy: 0.9908 - val_loss: 0.3279 - val_accuracy: 0.9018\n",
            "Epoch 97/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0987 - accuracy: 0.9931 - val_loss: 0.3211 - val_accuracy: 0.9018\n",
            "Epoch 98/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0976 - accuracy: 0.9931 - val_loss: 0.3272 - val_accuracy: 0.9018\n",
            "Epoch 99/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0981 - accuracy: 0.9908 - val_loss: 0.2932 - val_accuracy: 0.9196\n",
            "Epoch 100/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0994 - accuracy: 0.9908 - val_loss: 0.3030 - val_accuracy: 0.9018\n",
            "Epoch 101/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0966 - accuracy: 0.9908 - val_loss: 0.3428 - val_accuracy: 0.8929\n",
            "Epoch 102/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.1000 - accuracy: 0.9931 - val_loss: 0.3185 - val_accuracy: 0.9018\n",
            "Epoch 103/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0955 - accuracy: 0.9977 - val_loss: 0.3028 - val_accuracy: 0.9107\n",
            "Epoch 104/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0966 - accuracy: 0.9931 - val_loss: 0.3076 - val_accuracy: 0.9107\n",
            "Epoch 105/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0946 - accuracy: 0.9908 - val_loss: 0.3450 - val_accuracy: 0.8839\n",
            "Epoch 106/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0940 - accuracy: 0.9954 - val_loss: 0.3057 - val_accuracy: 0.9018\n",
            "Epoch 107/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0928 - accuracy: 0.9954 - val_loss: 0.3483 - val_accuracy: 0.8750\n",
            "Epoch 108/1000\n",
            "14/14 [==============================] - 4s 326ms/step - loss: 0.0928 - accuracy: 0.9977 - val_loss: 0.2931 - val_accuracy: 0.9107\n",
            "Epoch 109/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0967 - accuracy: 0.9931 - val_loss: 0.3366 - val_accuracy: 0.9018\n",
            "Epoch 110/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0963 - accuracy: 0.9908 - val_loss: 0.3631 - val_accuracy: 0.8750\n",
            "Epoch 111/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0933 - accuracy: 0.9931 - val_loss: 0.3307 - val_accuracy: 0.9018\n",
            "Epoch 112/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0955 - accuracy: 0.9908 - val_loss: 0.2848 - val_accuracy: 0.9196\n",
            "Epoch 113/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0922 - accuracy: 0.9931 - val_loss: 0.3192 - val_accuracy: 0.9018\n",
            "Epoch 114/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0907 - accuracy: 0.9954 - val_loss: 0.3677 - val_accuracy: 0.8750\n",
            "Epoch 115/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0920 - accuracy: 0.9931 - val_loss: 0.3349 - val_accuracy: 0.8839\n",
            "Epoch 116/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0920 - accuracy: 0.9977 - val_loss: 0.2992 - val_accuracy: 0.9107\n",
            "Epoch 117/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0884 - accuracy: 0.9954 - val_loss: 0.3290 - val_accuracy: 0.9018\n",
            "Epoch 118/1000\n",
            "14/14 [==============================] - 4s 326ms/step - loss: 0.0871 - accuracy: 0.9954 - val_loss: 0.3303 - val_accuracy: 0.9018\n",
            "Epoch 119/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0896 - accuracy: 0.9954 - val_loss: 0.3499 - val_accuracy: 0.8750\n",
            "Epoch 120/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0862 - accuracy: 0.9954 - val_loss: 0.3181 - val_accuracy: 0.9018\n",
            "Epoch 121/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0860 - accuracy: 0.9954 - val_loss: 0.3305 - val_accuracy: 0.9018\n",
            "Epoch 122/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0856 - accuracy: 0.9954 - val_loss: 0.3164 - val_accuracy: 0.9018\n",
            "Epoch 123/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0854 - accuracy: 0.9954 - val_loss: 0.3361 - val_accuracy: 0.8839\n",
            "Epoch 124/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0850 - accuracy: 0.9954 - val_loss: 0.3181 - val_accuracy: 0.9018\n",
            "Epoch 125/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0892 - accuracy: 0.9954 - val_loss: 0.3481 - val_accuracy: 0.8750\n",
            "Epoch 126/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0856 - accuracy: 0.9954 - val_loss: 0.3606 - val_accuracy: 0.8750\n",
            "Epoch 127/1000\n",
            "14/14 [==============================] - 4s 326ms/step - loss: 0.0838 - accuracy: 0.9977 - val_loss: 0.3134 - val_accuracy: 0.9018\n",
            "Epoch 128/1000\n",
            "14/14 [==============================] - 4s 329ms/step - loss: 0.0826 - accuracy: 0.9954 - val_loss: 0.3368 - val_accuracy: 0.8839\n",
            "Epoch 129/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0829 - accuracy: 0.9977 - val_loss: 0.3015 - val_accuracy: 0.9107\n",
            "Epoch 130/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0851 - accuracy: 0.9931 - val_loss: 0.3444 - val_accuracy: 0.8750\n",
            "Epoch 131/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0827 - accuracy: 0.9954 - val_loss: 0.3411 - val_accuracy: 0.8750\n",
            "Epoch 132/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0811 - accuracy: 0.9977 - val_loss: 0.2894 - val_accuracy: 0.9196\n",
            "Epoch 133/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0848 - accuracy: 0.9977 - val_loss: 0.3794 - val_accuracy: 0.8661\n",
            "Epoch 134/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0820 - accuracy: 0.9931 - val_loss: 0.3364 - val_accuracy: 0.8839\n",
            "Epoch 135/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0818 - accuracy: 0.9977 - val_loss: 0.2907 - val_accuracy: 0.9196\n",
            "Epoch 136/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0816 - accuracy: 0.9931 - val_loss: 0.3228 - val_accuracy: 0.9018\n",
            "Epoch 137/1000\n",
            "14/14 [==============================] - 4s 289ms/step - loss: 0.0796 - accuracy: 0.9977 - val_loss: 0.3047 - val_accuracy: 0.9018\n",
            "Epoch 138/1000\n",
            "14/14 [==============================] - 4s 326ms/step - loss: 0.0797 - accuracy: 0.9977 - val_loss: 0.3254 - val_accuracy: 0.9018\n",
            "Epoch 139/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0799 - accuracy: 0.9954 - val_loss: 0.3722 - val_accuracy: 0.8750\n",
            "Epoch 140/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0784 - accuracy: 0.9954 - val_loss: 0.3067 - val_accuracy: 0.9107\n",
            "Epoch 141/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0795 - accuracy: 0.9977 - val_loss: 0.3285 - val_accuracy: 0.9018\n",
            "Epoch 142/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0767 - accuracy: 0.9977 - val_loss: 0.3120 - val_accuracy: 0.9018\n",
            "Epoch 143/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0772 - accuracy: 0.9977 - val_loss: 0.3227 - val_accuracy: 0.9018\n",
            "Epoch 144/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0761 - accuracy: 0.9954 - val_loss: 0.3519 - val_accuracy: 0.8750\n",
            "Epoch 145/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0783 - accuracy: 0.9977 - val_loss: 0.3111 - val_accuracy: 0.9018\n",
            "Epoch 146/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0785 - accuracy: 0.9954 - val_loss: 0.3030 - val_accuracy: 0.9107\n",
            "Epoch 147/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0749 - accuracy: 0.9977 - val_loss: 0.3372 - val_accuracy: 0.8839\n",
            "Epoch 148/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0742 - accuracy: 0.9977 - val_loss: 0.3287 - val_accuracy: 0.9018\n",
            "Epoch 149/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0754 - accuracy: 0.9977 - val_loss: 0.2995 - val_accuracy: 0.9196\n",
            "Epoch 150/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0743 - accuracy: 0.9954 - val_loss: 0.3347 - val_accuracy: 0.8839\n",
            "Epoch 151/1000\n",
            "14/14 [==============================] - 4s 326ms/step - loss: 0.0732 - accuracy: 0.9977 - val_loss: 0.3514 - val_accuracy: 0.8750\n",
            "Epoch 152/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.3172 - val_accuracy: 0.9018\n",
            "Epoch 153/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0723 - accuracy: 0.9977 - val_loss: 0.3188 - val_accuracy: 0.9018\n",
            "Epoch 154/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0720 - accuracy: 0.9977 - val_loss: 0.3402 - val_accuracy: 0.8750\n",
            "Epoch 155/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0719 - accuracy: 0.9977 - val_loss: 0.3452 - val_accuracy: 0.8750\n",
            "Epoch 156/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.9018\n",
            "Epoch 157/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0709 - accuracy: 0.9977 - val_loss: 0.3450 - val_accuracy: 0.8750\n",
            "Epoch 158/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0711 - accuracy: 0.9977 - val_loss: 0.3297 - val_accuracy: 0.8929\n",
            "Epoch 159/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0697 - accuracy: 0.9977 - val_loss: 0.3435 - val_accuracy: 0.8750\n",
            "Epoch 160/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0695 - accuracy: 0.9977 - val_loss: 0.3231 - val_accuracy: 0.9018\n",
            "Epoch 161/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0692 - accuracy: 0.9977 - val_loss: 0.3338 - val_accuracy: 0.8839\n",
            "Epoch 162/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0694 - accuracy: 0.9977 - val_loss: 0.3142 - val_accuracy: 0.9018\n",
            "Epoch 163/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0692 - accuracy: 0.9977 - val_loss: 0.3553 - val_accuracy: 0.8750\n",
            "Epoch 164/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0683 - accuracy: 0.9977 - val_loss: 0.3183 - val_accuracy: 0.9018\n",
            "Epoch 165/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0679 - accuracy: 0.9977 - val_loss: 0.3241 - val_accuracy: 0.9018\n",
            "Epoch 166/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0678 - accuracy: 0.9977 - val_loss: 0.3273 - val_accuracy: 0.8929\n",
            "Epoch 167/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0672 - accuracy: 0.9977 - val_loss: 0.3503 - val_accuracy: 0.8750\n",
            "Epoch 168/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0669 - accuracy: 0.9977 - val_loss: 0.3251 - val_accuracy: 0.9018\n",
            "Epoch 169/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0696 - accuracy: 0.9977 - val_loss: 0.2824 - val_accuracy: 0.9196\n",
            "Epoch 170/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0685 - accuracy: 0.9977 - val_loss: 0.3299 - val_accuracy: 0.8839\n",
            "Epoch 171/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0655 - accuracy: 0.9977 - val_loss: 0.3079 - val_accuracy: 0.9018\n",
            "Epoch 172/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0681 - accuracy: 0.9977 - val_loss: 0.4029 - val_accuracy: 0.8661\n",
            "Epoch 173/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0664 - accuracy: 0.9977 - val_loss: 0.2985 - val_accuracy: 0.9196\n",
            "Epoch 174/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0666 - accuracy: 0.9977 - val_loss: 0.3163 - val_accuracy: 0.9018\n",
            "Epoch 175/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0641 - accuracy: 0.9977 - val_loss: 0.3587 - val_accuracy: 0.8750\n",
            "Epoch 176/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0644 - accuracy: 0.9977 - val_loss: 0.3287 - val_accuracy: 0.8929\n",
            "Epoch 177/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0646 - accuracy: 0.9977 - val_loss: 0.3141 - val_accuracy: 0.9018\n",
            "Epoch 178/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0652 - accuracy: 0.9977 - val_loss: 0.3517 - val_accuracy: 0.8750\n",
            "Epoch 179/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.8750\n",
            "Epoch 180/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0629 - accuracy: 0.9977 - val_loss: 0.3059 - val_accuracy: 0.9107\n",
            "Epoch 181/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 0.8929\n",
            "Epoch 182/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0620 - accuracy: 0.9977 - val_loss: 0.3289 - val_accuracy: 0.8929\n",
            "Epoch 183/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9196\n",
            "Epoch 184/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.8750\n",
            "Epoch 185/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0636 - accuracy: 0.9977 - val_loss: 0.3717 - val_accuracy: 0.8750\n",
            "Epoch 186/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0621 - accuracy: 0.9977 - val_loss: 0.3243 - val_accuracy: 0.8929\n",
            "Epoch 187/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.8750\n",
            "Epoch 188/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0611 - accuracy: 0.9977 - val_loss: 0.3704 - val_accuracy: 0.8750\n",
            "Epoch 189/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9196\n",
            "Epoch 190/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0601 - accuracy: 0.9977 - val_loss: 0.3763 - val_accuracy: 0.8750\n",
            "Epoch 191/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0618 - accuracy: 0.9977 - val_loss: 0.3437 - val_accuracy: 0.8839\n",
            "Epoch 192/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9107\n",
            "Epoch 193/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0588 - accuracy: 0.9977 - val_loss: 0.3661 - val_accuracy: 0.8750\n",
            "Epoch 194/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.8839\n",
            "Epoch 195/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0581 - accuracy: 0.9977 - val_loss: 0.3346 - val_accuracy: 0.8839\n",
            "Epoch 196/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.8839\n",
            "Epoch 197/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0574 - accuracy: 0.9977 - val_loss: 0.3377 - val_accuracy: 0.8839\n",
            "Epoch 198/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9107\n",
            "Epoch 199/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0576 - accuracy: 0.9977 - val_loss: 0.3331 - val_accuracy: 0.8839\n",
            "Epoch 200/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0578 - accuracy: 0.9977 - val_loss: 0.3405 - val_accuracy: 0.8839\n",
            "Epoch 201/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9196\n",
            "Epoch 202/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.8750\n",
            "Epoch 203/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0555 - accuracy: 0.9977 - val_loss: 0.3267 - val_accuracy: 0.8929\n",
            "Epoch 204/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.8839\n",
            "Epoch 205/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.8839\n",
            "Epoch 206/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.3365 - val_accuracy: 0.8839\n",
            "Epoch 207/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0546 - accuracy: 1.0000 - val_loss: 0.3232 - val_accuracy: 0.8929\n",
            "Epoch 208/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.8750\n",
            "Epoch 209/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.3548 - val_accuracy: 0.8750\n",
            "Epoch 210/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.8839\n",
            "Epoch 211/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.8839\n",
            "Epoch 212/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.8750\n",
            "Epoch 213/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.8839\n",
            "Epoch 214/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 0.8929\n",
            "Epoch 215/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.8750\n",
            "Epoch 216/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.8839\n",
            "Epoch 217/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.8929\n",
            "Epoch 218/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.8839\n",
            "Epoch 219/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.8750\n",
            "Epoch 220/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.8929\n",
            "Epoch 221/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 0.8750\n",
            "Epoch 222/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.8839\n",
            "Epoch 223/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.8839\n",
            "Epoch 224/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.3139 - val_accuracy: 0.9018\n",
            "Epoch 225/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.8750\n",
            "Epoch 226/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.8839\n",
            "Epoch 227/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.8750\n",
            "Epoch 228/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.8839\n",
            "Epoch 229/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.8839\n",
            "Epoch 230/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.8839\n",
            "Epoch 231/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.8839\n",
            "Epoch 232/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.8929\n",
            "Epoch 233/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.3377 - val_accuracy: 0.8839\n",
            "Epoch 234/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.8839\n",
            "Epoch 235/1000\n",
            "14/14 [==============================] - 4s 329ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.8839\n",
            "Epoch 236/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.3254 - val_accuracy: 0.8929\n",
            "Epoch 237/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.3796 - val_accuracy: 0.8750\n",
            "Epoch 238/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.8750\n",
            "Epoch 239/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.9196\n",
            "Epoch 240/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.8750\n",
            "Epoch 241/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.8929\n",
            "Epoch 242/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.8750\n",
            "Epoch 243/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.8750\n",
            "Epoch 244/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.8839\n",
            "Epoch 245/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.8839\n",
            "Epoch 246/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.8839\n",
            "Epoch 247/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.8839\n",
            "Epoch 248/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.8839\n",
            "Epoch 249/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.8750\n",
            "Epoch 250/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.8839\n",
            "Epoch 251/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.8750\n",
            "Epoch 252/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.8839\n",
            "Epoch 253/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.8839\n",
            "Epoch 254/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.3406 - val_accuracy: 0.8839\n",
            "Epoch 255/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.8839\n",
            "Epoch 256/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.8839\n",
            "Epoch 257/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.8839\n",
            "Epoch 258/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.8839\n",
            "Epoch 259/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.8750\n",
            "Epoch 260/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.8750\n",
            "Epoch 261/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.8929\n",
            "Epoch 262/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.8750\n",
            "Epoch 263/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.8929\n",
            "Epoch 264/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9107\n",
            "Epoch 265/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.8750\n",
            "Epoch 266/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9107\n",
            "Epoch 267/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.8750\n",
            "Epoch 268/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.8839\n",
            "Epoch 269/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.8750\n",
            "Epoch 270/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.8839\n",
            "Epoch 271/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.8750\n",
            "Epoch 272/1000\n",
            "14/14 [==============================] - 4s 303ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.8839\n",
            "Epoch 273/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.8839\n",
            "Epoch 274/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.8839\n",
            "Epoch 275/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.8839\n",
            "Epoch 276/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.8750\n",
            "Epoch 277/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.8750\n",
            "Epoch 278/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.8839\n",
            "Epoch 279/1000\n",
            "14/14 [==============================] - 4s 307ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.8839\n",
            "Epoch 280/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.8750\n",
            "Epoch 281/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.8750\n",
            "Epoch 282/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9018\n",
            "Epoch 283/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.8839\n",
            "Epoch 284/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.8750\n",
            "Epoch 285/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.8929\n",
            "Epoch 286/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.8839\n",
            "Epoch 287/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.8750\n",
            "Epoch 288/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.8839\n",
            "Epoch 289/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.8839\n",
            "Epoch 290/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.8839\n",
            "Epoch 291/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.8839\n",
            "Epoch 292/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.8839\n",
            "Epoch 293/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.8839\n",
            "Epoch 294/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.8839\n",
            "Epoch 295/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.8839\n",
            "Epoch 296/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.8839\n",
            "Epoch 297/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.8750\n",
            "Epoch 298/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.8839\n",
            "Epoch 299/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.8839\n",
            "Epoch 300/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.8750\n",
            "Epoch 301/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.8839\n",
            "Epoch 302/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.8839\n",
            "Epoch 303/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.8839\n",
            "Epoch 304/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.8839\n",
            "Epoch 305/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.8839\n",
            "Epoch 306/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.8750\n",
            "Epoch 307/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.8839\n",
            "Epoch 308/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.8750\n",
            "Epoch 309/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.8839\n",
            "Epoch 310/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.3545 - val_accuracy: 0.8839\n",
            "Epoch 311/1000\n",
            "14/14 [==============================] - 4s 326ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.8750\n",
            "Epoch 312/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.8839\n",
            "Epoch 313/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.8839\n",
            "Epoch 314/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.8839\n",
            "Epoch 315/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.8839\n",
            "Epoch 316/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.9196\n",
            "Epoch 317/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.8750\n",
            "Epoch 318/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.8750\n",
            "Epoch 319/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.8839\n",
            "Epoch 320/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.8839\n",
            "Epoch 321/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.8839\n",
            "Epoch 322/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.8839\n",
            "Epoch 323/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.8839\n",
            "Epoch 324/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.8839\n",
            "Epoch 325/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.8750\n",
            "Epoch 326/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.8839\n",
            "Epoch 327/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.8750\n",
            "Epoch 328/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.8839\n",
            "Epoch 329/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9018\n",
            "Epoch 330/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9018\n",
            "Epoch 331/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.3976 - val_accuracy: 0.8750\n",
            "Epoch 332/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.8839\n",
            "Epoch 333/1000\n",
            "14/14 [==============================] - 5s 340ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.8839\n",
            "Epoch 334/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.8839\n",
            "Epoch 335/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.8929\n",
            "Epoch 336/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.8750\n",
            "Epoch 337/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.8750\n",
            "Epoch 338/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.8839\n",
            "Epoch 339/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.8750\n",
            "Epoch 340/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.8839\n",
            "Epoch 341/1000\n",
            "14/14 [==============================] - 4s 327ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.8839\n",
            "Epoch 342/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.8750\n",
            "Epoch 343/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.8839\n",
            "Epoch 344/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.8750\n",
            "Epoch 345/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.8750\n",
            "Epoch 346/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 0.9196\n",
            "Epoch 347/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.9018\n",
            "Epoch 348/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.8750\n",
            "Epoch 349/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.8839\n",
            "Epoch 350/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.8839\n",
            "Epoch 351/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.8839\n",
            "Epoch 352/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.8750\n",
            "Epoch 353/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.8750\n",
            "Epoch 354/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.8839\n",
            "Epoch 355/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.8839\n",
            "Epoch 356/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.8929\n",
            "Epoch 357/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.8839\n",
            "Epoch 358/1000\n",
            "14/14 [==============================] - 4s 290ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.8839\n",
            "Epoch 359/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.8750\n",
            "Epoch 360/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9018\n",
            "Epoch 361/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.8750\n",
            "Epoch 362/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9018\n",
            "Epoch 363/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.8750\n",
            "Epoch 364/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.8839\n",
            "Epoch 365/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.9107\n",
            "Epoch 366/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.8750\n",
            "Epoch 367/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.8839\n",
            "Epoch 368/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.8839\n",
            "Epoch 369/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.8750\n",
            "Epoch 370/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.8839\n",
            "Epoch 371/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8750\n",
            "Epoch 372/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.8929\n",
            "Epoch 373/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.8839\n",
            "Epoch 374/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.8750\n",
            "Epoch 375/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.8839\n",
            "Epoch 376/1000\n",
            "14/14 [==============================] - 4s 305ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.8750\n",
            "Epoch 377/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.8750\n",
            "Epoch 378/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.8839\n",
            "Epoch 379/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.8839\n",
            "Epoch 380/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9107\n",
            "Epoch 381/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8750\n",
            "Epoch 382/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.8929\n",
            "Epoch 383/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.8929\n",
            "Epoch 384/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.3643 - val_accuracy: 0.8839\n",
            "Epoch 385/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.8839\n",
            "Epoch 386/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.8839\n",
            "Epoch 387/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.8750\n",
            "Epoch 388/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.8839\n",
            "Epoch 389/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.8839\n",
            "Epoch 390/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.8839\n",
            "Epoch 391/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.8750\n",
            "Epoch 392/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.3287 - val_accuracy: 0.9196\n",
            "Epoch 393/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.8750\n",
            "Epoch 394/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.9107\n",
            "Epoch 395/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.3684 - val_accuracy: 0.8839\n",
            "Epoch 396/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.8750\n",
            "Epoch 397/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.8839\n",
            "Epoch 398/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.8839\n",
            "Epoch 399/1000\n",
            "14/14 [==============================] - 5s 340ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.8839\n",
            "Epoch 400/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.8929\n",
            "Epoch 401/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.8750\n",
            "Epoch 402/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.8929\n",
            "Epoch 403/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.8750\n",
            "Epoch 404/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.8750\n",
            "Epoch 405/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.9018\n",
            "Epoch 406/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.3707 - val_accuracy: 0.8839\n",
            "Epoch 407/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8750\n",
            "Epoch 408/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.8929\n",
            "Epoch 409/1000\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.8750\n",
            "Epoch 410/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.8839\n",
            "Epoch 411/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.8839\n",
            "Epoch 412/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.8750\n",
            "Epoch 413/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.8839\n",
            "Epoch 414/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.8929\n",
            "Epoch 415/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.8750\n",
            "Epoch 416/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.8929\n",
            "Epoch 417/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.8750\n",
            "Epoch 418/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.3710 - val_accuracy: 0.8929\n",
            "Epoch 419/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.3905 - val_accuracy: 0.8750\n",
            "Epoch 420/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.8839\n",
            "Epoch 421/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.8750\n",
            "Epoch 422/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9018\n",
            "Epoch 423/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.8750\n",
            "Epoch 424/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.8929\n",
            "Epoch 425/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.3691 - val_accuracy: 0.8929\n",
            "Epoch 426/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.8929\n",
            "Epoch 427/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.8750\n",
            "Epoch 428/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.8750\n",
            "Epoch 429/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.9018\n",
            "Epoch 430/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.8750\n",
            "Epoch 431/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.8750\n",
            "Epoch 432/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.8839\n",
            "Epoch 433/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.8929\n",
            "Epoch 434/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.8929\n",
            "Epoch 435/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.4050 - val_accuracy: 0.8750\n",
            "Epoch 436/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.8929\n",
            "Epoch 437/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.8929\n",
            "Epoch 438/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.8750\n",
            "Epoch 439/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.8750\n",
            "Epoch 440/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.8929\n",
            "Epoch 441/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.8750\n",
            "Epoch 442/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.8929\n",
            "Epoch 443/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.8929\n",
            "Epoch 444/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9018\n",
            "Epoch 445/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.8750\n",
            "Epoch 446/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.8929\n",
            "Epoch 447/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.3952 - val_accuracy: 0.8750\n",
            "Epoch 448/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.3735 - val_accuracy: 0.8929\n",
            "Epoch 449/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.8750\n",
            "Epoch 450/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.8929\n",
            "Epoch 451/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.8839\n",
            "Epoch 452/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.8750\n",
            "Epoch 453/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.8929\n",
            "Epoch 454/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.8750\n",
            "Epoch 455/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3713 - val_accuracy: 0.8929\n",
            "Epoch 456/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.8750\n",
            "Epoch 457/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.8929\n",
            "Epoch 458/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.8929\n",
            "Epoch 459/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.8929\n",
            "Epoch 460/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.8929\n",
            "Epoch 461/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.8929\n",
            "Epoch 462/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.8750\n",
            "Epoch 463/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9018\n",
            "Epoch 464/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.8750\n",
            "Epoch 465/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.8750\n",
            "Epoch 466/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9018\n",
            "Epoch 467/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.8929\n",
            "Epoch 468/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.8750\n",
            "Epoch 469/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.8750\n",
            "Epoch 470/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.8929\n",
            "Epoch 471/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.8750\n",
            "Epoch 472/1000\n",
            "14/14 [==============================] - 4s 303ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.8839\n",
            "Epoch 473/1000\n",
            "14/14 [==============================] - 4s 303ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.8929\n",
            "Epoch 474/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.8929\n",
            "Epoch 475/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.8750\n",
            "Epoch 476/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8750\n",
            "Epoch 477/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.8750\n",
            "Epoch 478/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.8929\n",
            "Epoch 479/1000\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.8839\n",
            "Epoch 480/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.8750\n",
            "Epoch 481/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.8929\n",
            "Epoch 482/1000\n",
            "14/14 [==============================] - 4s 305ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.8929\n",
            "Epoch 483/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.8750\n",
            "Epoch 484/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.8929\n",
            "Epoch 485/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.3883 - val_accuracy: 0.8929\n",
            "Epoch 486/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.8929\n",
            "Epoch 487/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.8839\n",
            "Epoch 488/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.8929\n",
            "Epoch 489/1000\n",
            "14/14 [==============================] - 4s 303ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.8929\n",
            "Epoch 490/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.8929\n",
            "Epoch 491/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.8929\n",
            "Epoch 492/1000\n",
            "14/14 [==============================] - 4s 308ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.8750\n",
            "Epoch 493/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.8750\n",
            "Epoch 494/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.8929\n",
            "Epoch 495/1000\n",
            "14/14 [==============================] - 4s 303ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.8929\n",
            "Epoch 496/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.8750\n",
            "Epoch 497/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.3905 - val_accuracy: 0.8929\n",
            "Epoch 498/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.8750\n",
            "Epoch 499/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.8929\n",
            "Epoch 500/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.8750\n",
            "Epoch 501/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.8929\n",
            "Epoch 502/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.9018\n",
            "Epoch 503/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.8929\n",
            "Epoch 504/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.8839\n",
            "Epoch 505/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.8839\n",
            "Epoch 506/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.8839\n",
            "Epoch 507/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.8929\n",
            "Epoch 508/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.8929\n",
            "Epoch 509/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.8929\n",
            "Epoch 510/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.8750\n",
            "Epoch 511/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.3859 - val_accuracy: 0.8929\n",
            "Epoch 512/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.8929\n",
            "Epoch 513/1000\n",
            "14/14 [==============================] - 4s 329ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.8839\n",
            "Epoch 514/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.8929\n",
            "Epoch 515/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.8839\n",
            "Epoch 516/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.8929\n",
            "Epoch 517/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.8839\n",
            "Epoch 518/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.8750\n",
            "Epoch 519/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.8929\n",
            "Epoch 520/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.8929\n",
            "Epoch 521/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.8750\n",
            "Epoch 522/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.8929\n",
            "Epoch 523/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.8929\n",
            "Epoch 524/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.8750\n",
            "Epoch 525/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.8929\n",
            "Epoch 526/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.8929\n",
            "Epoch 527/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.8929\n",
            "Epoch 528/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.8929\n",
            "Epoch 529/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.8929\n",
            "Epoch 530/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.8750\n",
            "Epoch 531/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.8929\n",
            "Epoch 532/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.8661\n",
            "Epoch 533/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.3837 - val_accuracy: 0.9018\n",
            "Epoch 534/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.8839\n",
            "Epoch 535/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.8929\n",
            "Epoch 536/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.8929\n",
            "Epoch 537/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.8929\n",
            "Epoch 538/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.8839\n",
            "Epoch 539/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.9018\n",
            "Epoch 540/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.8839\n",
            "Epoch 541/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.8929\n",
            "Epoch 542/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.8750\n",
            "Epoch 543/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9018\n",
            "Epoch 544/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.8839\n",
            "Epoch 545/1000\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.8929\n",
            "Epoch 546/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.8750\n",
            "Epoch 547/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.8929\n",
            "Epoch 548/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.8839\n",
            "Epoch 549/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.8929\n",
            "Epoch 550/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.8929\n",
            "Epoch 551/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.8750\n",
            "Epoch 552/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.8929\n",
            "Epoch 553/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.8929\n",
            "Epoch 554/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.8929\n",
            "Epoch 555/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.8929\n",
            "Epoch 556/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.8929\n",
            "Epoch 557/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.8929\n",
            "Epoch 558/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.8929\n",
            "Epoch 559/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.8929\n",
            "Epoch 560/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.8839\n",
            "Epoch 561/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.8929\n",
            "Epoch 562/1000\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.8839\n",
            "Epoch 563/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.8839\n",
            "Epoch 564/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.8929\n",
            "Epoch 565/1000\n",
            "14/14 [==============================] - 4s 307ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.8929\n",
            "Epoch 566/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.8929\n",
            "Epoch 567/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.8839\n",
            "Epoch 568/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.8929\n",
            "Epoch 569/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.8929\n",
            "Epoch 570/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.8839\n",
            "Epoch 571/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.8839\n",
            "Epoch 572/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.8839\n",
            "Epoch 573/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.8839\n",
            "Epoch 574/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.8839\n",
            "Epoch 575/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.8929\n",
            "Epoch 576/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.8929\n",
            "Epoch 577/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.8839\n",
            "Epoch 578/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.8929\n",
            "Epoch 579/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.8839\n",
            "Epoch 580/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.8929\n",
            "Epoch 581/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.8929\n",
            "Epoch 582/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.8839\n",
            "Epoch 583/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.8929\n",
            "Epoch 584/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.8661\n",
            "Epoch 585/1000\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.9018\n",
            "Epoch 586/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.8839\n",
            "Epoch 587/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.8929\n",
            "Epoch 588/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.9018\n",
            "Epoch 589/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.8839\n",
            "Epoch 590/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.8839\n",
            "Epoch 591/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.8929\n",
            "Epoch 592/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.8929\n",
            "Epoch 593/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.8839\n",
            "Epoch 594/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.8839\n",
            "Epoch 595/1000\n",
            "14/14 [==============================] - 4s 303ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.8929\n",
            "Epoch 596/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.8839\n",
            "Epoch 597/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.8839\n",
            "Epoch 598/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.9018\n",
            "Epoch 599/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.8839\n",
            "Epoch 600/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.8839\n",
            "Epoch 601/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 0.8929\n",
            "Epoch 602/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.9018\n",
            "Epoch 603/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.8571\n",
            "Epoch 604/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.9107\n",
            "Epoch 605/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.8839\n",
            "Epoch 606/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4540 - val_accuracy: 0.8839\n",
            "Epoch 607/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.9018\n",
            "Epoch 608/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.8929\n",
            "Epoch 609/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.8929\n",
            "Epoch 610/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.8929\n",
            "Epoch 611/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.8839\n",
            "Epoch 612/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.8929\n",
            "Epoch 613/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.8929\n",
            "Epoch 614/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.8839\n",
            "Epoch 615/1000\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.8929\n",
            "Epoch 616/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.8839\n",
            "Epoch 617/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.9018\n",
            "Epoch 618/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.8839\n",
            "Epoch 619/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.8839\n",
            "Epoch 620/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.8839\n",
            "Epoch 621/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.8929\n",
            "Epoch 622/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.8929\n",
            "Epoch 623/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.8839\n",
            "Epoch 624/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.8929\n",
            "Epoch 625/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.8929\n",
            "Epoch 626/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.8929\n",
            "Epoch 627/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.8929\n",
            "Epoch 628/1000\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.8839\n",
            "Epoch 629/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.8929\n",
            "Epoch 630/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.8839\n",
            "Epoch 631/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.9018\n",
            "Epoch 632/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.8839\n",
            "Epoch 633/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.8839\n",
            "Epoch 634/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.8929\n",
            "Epoch 635/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.8929\n",
            "Epoch 636/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.8929\n",
            "Epoch 637/1000\n",
            "14/14 [==============================] - 4s 329ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.8929\n",
            "Epoch 638/1000\n",
            "14/14 [==============================] - 4s 305ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 0.8929\n",
            "Epoch 639/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.8929\n",
            "Epoch 640/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.8839\n",
            "Epoch 641/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.8839\n",
            "Epoch 642/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.8839\n",
            "Epoch 643/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.8839\n",
            "Epoch 644/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.8929\n",
            "Epoch 645/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.8839\n",
            "Epoch 646/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.8929\n",
            "Epoch 647/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.8929\n",
            "Epoch 648/1000\n",
            "14/14 [==============================] - 4s 305ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.8929\n",
            "Epoch 649/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.8929\n",
            "Epoch 650/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.8929\n",
            "Epoch 651/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.8929\n",
            "Epoch 652/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.8839\n",
            "Epoch 653/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.9018\n",
            "Epoch 654/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.8839\n",
            "Epoch 655/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.8839\n",
            "Epoch 656/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.9018\n",
            "Epoch 657/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.8839\n",
            "Epoch 658/1000\n",
            "14/14 [==============================] - 4s 305ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.8929\n",
            "Epoch 659/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9018\n",
            "Epoch 660/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.8929\n",
            "Epoch 661/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.9018\n",
            "Epoch 662/1000\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.8839\n",
            "Epoch 663/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4404 - val_accuracy: 0.8929\n",
            "Epoch 664/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.8929\n",
            "Epoch 665/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4551 - val_accuracy: 0.8839\n",
            "Epoch 666/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.8839\n",
            "Epoch 667/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.8929\n",
            "Epoch 668/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.8929\n",
            "Epoch 669/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.8839\n",
            "Epoch 670/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.8929\n",
            "Epoch 671/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.8839\n",
            "Epoch 672/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.8929\n",
            "Epoch 673/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.8750\n",
            "Epoch 674/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.8929\n",
            "Epoch 675/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.8750\n",
            "Epoch 676/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.8839\n",
            "Epoch 677/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.8929\n",
            "Epoch 678/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4745 - val_accuracy: 0.8839\n",
            "Epoch 679/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.8839\n",
            "Epoch 680/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.8929\n",
            "Epoch 681/1000\n",
            "14/14 [==============================] - 4s 303ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.8929\n",
            "Epoch 682/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.8750\n",
            "Epoch 683/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.8839\n",
            "Epoch 684/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.8929\n",
            "Epoch 685/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4596 - val_accuracy: 0.8929\n",
            "Epoch 686/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.8929\n",
            "Epoch 687/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4598 - val_accuracy: 0.8839\n",
            "Epoch 688/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.8929\n",
            "Epoch 689/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.8839\n",
            "Epoch 690/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.8929\n",
            "Epoch 691/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4642 - val_accuracy: 0.8839\n",
            "Epoch 692/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.8929\n",
            "Epoch 693/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.8929\n",
            "Epoch 694/1000\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.8839\n",
            "Epoch 695/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.8929\n",
            "Epoch 696/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.8929\n",
            "Epoch 697/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.8929\n",
            "Epoch 698/1000\n",
            "14/14 [==============================] - 5s 340ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.8839\n",
            "Epoch 699/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.8839\n",
            "Epoch 700/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.8750\n",
            "Epoch 701/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.9018\n",
            "Epoch 702/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.8929\n",
            "Epoch 703/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.8929\n",
            "Epoch 704/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.8929\n",
            "Epoch 705/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.8839\n",
            "Epoch 706/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.8929\n",
            "Epoch 707/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.8929\n",
            "Epoch 708/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.8839\n",
            "Epoch 709/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.8929\n",
            "Epoch 710/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.8750\n",
            "Epoch 711/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.8929\n",
            "Epoch 712/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.8929\n",
            "Epoch 713/1000\n",
            "14/14 [==============================] - 4s 328ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4784 - val_accuracy: 0.8839\n",
            "Epoch 714/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9018\n",
            "Epoch 715/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.8839\n",
            "Epoch 716/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9018\n",
            "Epoch 717/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.8750\n",
            "Epoch 718/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.8929\n",
            "Epoch 719/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.8839\n",
            "Epoch 720/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.8839\n",
            "Epoch 721/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.9018\n",
            "Epoch 722/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.8929\n",
            "Epoch 723/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.8929\n",
            "Epoch 724/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4771 - val_accuracy: 0.8839\n",
            "Epoch 725/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.9018\n",
            "Epoch 726/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.8750\n",
            "Epoch 727/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8929\n",
            "Epoch 728/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9018\n",
            "Epoch 729/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.8750\n",
            "Epoch 730/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.8929\n",
            "Epoch 731/1000\n",
            "14/14 [==============================] - 4s 305ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.8929\n",
            "Epoch 732/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.8929\n",
            "Epoch 733/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4815 - val_accuracy: 0.8839\n",
            "Epoch 734/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.8929\n",
            "Epoch 735/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.8839\n",
            "Epoch 736/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.8929\n",
            "Epoch 737/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9018\n",
            "Epoch 738/1000\n",
            "14/14 [==============================] - 5s 340ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.8929\n",
            "Epoch 739/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.8839\n",
            "Epoch 740/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.8929\n",
            "Epoch 741/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.8929\n",
            "Epoch 742/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4681 - val_accuracy: 0.8929\n",
            "Epoch 743/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.8929\n",
            "Epoch 744/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.8839\n",
            "Epoch 745/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.8929\n",
            "Epoch 746/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.8929\n",
            "Epoch 747/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.9018\n",
            "Epoch 748/1000\n",
            "14/14 [==============================] - 5s 340ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.8839\n",
            "Epoch 749/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.8929\n",
            "Epoch 750/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.8929\n",
            "Epoch 751/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.8929\n",
            "Epoch 752/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.8929\n",
            "Epoch 753/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.8750\n",
            "Epoch 754/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.9018\n",
            "Epoch 755/1000\n",
            "14/14 [==============================] - 5s 340ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.8929\n",
            "Epoch 756/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.8929\n",
            "Epoch 757/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.8929\n",
            "Epoch 758/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4806 - val_accuracy: 0.8929\n",
            "Epoch 759/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4688 - val_accuracy: 0.8929\n",
            "Epoch 760/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.8839\n",
            "Epoch 761/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.8929\n",
            "Epoch 762/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.8839\n",
            "Epoch 763/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.8929\n",
            "Epoch 764/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.8839\n",
            "Epoch 765/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.8839\n",
            "Epoch 766/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.8929\n",
            "Epoch 767/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.8750\n",
            "Epoch 768/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.8929\n",
            "Epoch 769/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.8839\n",
            "Epoch 770/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.8929\n",
            "Epoch 771/1000\n",
            "14/14 [==============================] - 4s 306ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.8750\n",
            "Epoch 772/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.8929\n",
            "Epoch 773/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.8839\n",
            "Epoch 774/1000\n",
            "14/14 [==============================] - 5s 340ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.8929\n",
            "Epoch 775/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.8839\n",
            "Epoch 776/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.8929\n",
            "Epoch 777/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.8929\n",
            "Epoch 778/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.8750\n",
            "Epoch 779/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.8929\n",
            "Epoch 780/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.8929\n",
            "Epoch 781/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.9018\n",
            "Epoch 782/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4958 - val_accuracy: 0.8839\n",
            "Epoch 783/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.8929\n",
            "Epoch 784/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.8929\n",
            "Epoch 785/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.8929\n",
            "Epoch 786/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.8839\n",
            "Epoch 787/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.8929\n",
            "Epoch 788/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.8929\n",
            "Epoch 789/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.8929\n",
            "Epoch 790/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5144 - val_accuracy: 0.8750\n",
            "Epoch 791/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.8929\n",
            "Epoch 792/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.8750\n",
            "Epoch 793/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9018\n",
            "Epoch 794/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.8750\n",
            "Epoch 795/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.9018\n",
            "Epoch 796/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.8750\n",
            "Epoch 797/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.8750\n",
            "Epoch 798/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.8929\n",
            "Epoch 799/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4801 - val_accuracy: 0.8929\n",
            "Epoch 800/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.8929\n",
            "Epoch 801/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.8929\n",
            "Epoch 802/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8750\n",
            "Epoch 803/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4763 - val_accuracy: 0.8929\n",
            "Epoch 804/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9018\n",
            "Epoch 805/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.8839\n",
            "Epoch 806/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.8929\n",
            "Epoch 807/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.8929\n",
            "Epoch 808/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.8929\n",
            "Epoch 809/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.8839\n",
            "Epoch 810/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.8929\n",
            "Epoch 811/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4768 - val_accuracy: 0.8929\n",
            "Epoch 812/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.8839\n",
            "Epoch 813/1000\n",
            "14/14 [==============================] - 5s 340ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.8929\n",
            "Epoch 814/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5198 - val_accuracy: 0.8750\n",
            "Epoch 815/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.8929\n",
            "Epoch 816/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8929\n",
            "Epoch 817/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.8929\n",
            "Epoch 818/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.8929\n",
            "Epoch 819/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5150 - val_accuracy: 0.8750\n",
            "Epoch 820/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5019 - val_accuracy: 0.8839\n",
            "Epoch 821/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4706 - val_accuracy: 0.8929\n",
            "Epoch 822/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5140 - val_accuracy: 0.8750\n",
            "Epoch 823/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4949 - val_accuracy: 0.8929\n",
            "Epoch 824/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.8750\n",
            "Epoch 825/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.8929\n",
            "Epoch 826/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.8929\n",
            "Epoch 827/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4871 - val_accuracy: 0.8929\n",
            "Epoch 828/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.9018\n",
            "Epoch 829/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5308 - val_accuracy: 0.8750\n",
            "Epoch 830/1000\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.8929\n",
            "Epoch 831/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.8839\n",
            "Epoch 832/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.8929\n",
            "Epoch 833/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5050 - val_accuracy: 0.8839\n",
            "Epoch 834/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.8929\n",
            "Epoch 835/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5355 - val_accuracy: 0.8750\n",
            "Epoch 836/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.8839\n",
            "Epoch 837/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.8929\n",
            "Epoch 838/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.8750\n",
            "Epoch 839/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.8929\n",
            "Epoch 840/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5174 - val_accuracy: 0.8750\n",
            "Epoch 841/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.9018\n",
            "Epoch 842/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5374 - val_accuracy: 0.8750\n",
            "Epoch 843/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.8929\n",
            "Epoch 844/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4934 - val_accuracy: 0.8929\n",
            "Epoch 845/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.8929\n",
            "Epoch 846/1000\n",
            "14/14 [==============================] - 4s 307ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.9018\n",
            "Epoch 847/1000\n",
            "14/14 [==============================] - 4s 306ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.8750\n",
            "Epoch 848/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9018\n",
            "Epoch 849/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.8750\n",
            "Epoch 850/1000\n",
            "14/14 [==============================] - 5s 340ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5062 - val_accuracy: 0.8839\n",
            "Epoch 851/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.8839\n",
            "Epoch 852/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.8929\n",
            "Epoch 853/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.8929\n",
            "Epoch 854/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.8839\n",
            "Epoch 855/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.8929\n",
            "Epoch 856/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.8929\n",
            "Epoch 857/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.8929\n",
            "Epoch 858/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.8839\n",
            "Epoch 859/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4787 - val_accuracy: 0.9018\n",
            "Epoch 860/1000\n",
            "14/14 [==============================] - 4s 303ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.8750\n",
            "Epoch 861/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.8929\n",
            "Epoch 862/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.8929\n",
            "Epoch 863/1000\n",
            "14/14 [==============================] - 5s 340ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5015 - val_accuracy: 0.8929\n",
            "Epoch 864/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.8929\n",
            "Epoch 865/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.9018\n",
            "Epoch 866/1000\n",
            "14/14 [==============================] - 4s 303ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5328 - val_accuracy: 0.8750\n",
            "Epoch 867/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.8750\n",
            "Epoch 868/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.9018\n",
            "Epoch 869/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5271 - val_accuracy: 0.8750\n",
            "Epoch 870/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.8929\n",
            "Epoch 871/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.8929\n",
            "Epoch 872/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.8929\n",
            "Epoch 873/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5308 - val_accuracy: 0.8750\n",
            "Epoch 874/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5334 - val_accuracy: 0.8750\n",
            "Epoch 875/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.8929\n",
            "Epoch 876/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5208 - val_accuracy: 0.8750\n",
            "Epoch 877/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.8839\n",
            "Epoch 878/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.9018\n",
            "Epoch 879/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.8750\n",
            "Epoch 880/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5291 - val_accuracy: 0.8750\n",
            "Epoch 881/1000\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5229 - val_accuracy: 0.8750\n",
            "Epoch 882/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.8839\n",
            "Epoch 883/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5352 - val_accuracy: 0.8750\n",
            "Epoch 884/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.8929\n",
            "Epoch 885/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5198 - val_accuracy: 0.8839\n",
            "Epoch 886/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.9018\n",
            "Epoch 887/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5398 - val_accuracy: 0.8750\n",
            "Epoch 888/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5156 - val_accuracy: 0.8839\n",
            "Epoch 889/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.8750\n",
            "Epoch 890/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.9018\n",
            "Epoch 891/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5314 - val_accuracy: 0.8750\n",
            "Epoch 892/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.8839\n",
            "Epoch 893/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.8929\n",
            "Epoch 894/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.9018\n",
            "Epoch 895/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5691 - val_accuracy: 0.8750\n",
            "Epoch 896/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.9018\n",
            "Epoch 897/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.8750\n",
            "Epoch 898/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.8929\n",
            "Epoch 899/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5224 - val_accuracy: 0.8839\n",
            "Epoch 900/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.9018\n",
            "Epoch 901/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.8929\n",
            "Epoch 902/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.8750\n",
            "Epoch 903/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5122 - val_accuracy: 0.8929\n",
            "Epoch 904/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5424 - val_accuracy: 0.8750\n",
            "Epoch 905/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.9018\n",
            "Epoch 906/1000\n",
            "14/14 [==============================] - 4s 303ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5508 - val_accuracy: 0.8750\n",
            "Epoch 907/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9018\n",
            "Epoch 908/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.8750\n",
            "Epoch 909/1000\n",
            "14/14 [==============================] - 4s 305ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.8839\n",
            "Epoch 910/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5307 - val_accuracy: 0.8750\n",
            "Epoch 911/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.8929\n",
            "Epoch 912/1000\n",
            "14/14 [==============================] - 5s 338ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.8750\n",
            "Epoch 913/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5232 - val_accuracy: 0.8839\n",
            "Epoch 914/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.9018\n",
            "Epoch 915/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.8929\n",
            "Epoch 916/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.8750\n",
            "Epoch 917/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5221 - val_accuracy: 0.8929\n",
            "Epoch 918/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.8929\n",
            "Epoch 919/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.8750\n",
            "Epoch 920/1000\n",
            "14/14 [==============================] - 4s 292ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5361 - val_accuracy: 0.8750\n",
            "Epoch 921/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5393 - val_accuracy: 0.8750\n",
            "Epoch 922/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.8929\n",
            "Epoch 923/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5555 - val_accuracy: 0.8750\n",
            "Epoch 924/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5264 - val_accuracy: 0.8929\n",
            "Epoch 925/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.9018\n",
            "Epoch 926/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5679 - val_accuracy: 0.8750\n",
            "Epoch 927/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 0.8929\n",
            "Epoch 928/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5288 - val_accuracy: 0.8839\n",
            "Epoch 929/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5245 - val_accuracy: 0.8839\n",
            "Epoch 930/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.8929\n",
            "Epoch 931/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.8750\n",
            "Epoch 932/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.8929\n",
            "Epoch 933/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.8750\n",
            "Epoch 934/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.9018\n",
            "Epoch 935/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.8750\n",
            "Epoch 936/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5163 - val_accuracy: 0.8929\n",
            "Epoch 937/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.8929\n",
            "Epoch 938/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5416 - val_accuracy: 0.8750\n",
            "Epoch 939/1000\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5250 - val_accuracy: 0.8929\n",
            "Epoch 940/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5246 - val_accuracy: 0.8929\n",
            "Epoch 941/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5591 - val_accuracy: 0.8750\n",
            "Epoch 942/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.9018\n",
            "Epoch 943/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5573 - val_accuracy: 0.8750\n",
            "Epoch 944/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5442 - val_accuracy: 0.8750\n",
            "Epoch 945/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5419 - val_accuracy: 0.8750\n",
            "Epoch 946/1000\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9018\n",
            "Epoch 947/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.8750\n",
            "Epoch 948/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.8839\n",
            "Epoch 949/1000\n",
            "14/14 [==============================] - 4s 304ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.8929\n",
            "Epoch 950/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5686 - val_accuracy: 0.8750\n",
            "Epoch 951/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.8929\n",
            "Epoch 952/1000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.8929\n",
            "Epoch 953/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5546 - val_accuracy: 0.8750\n",
            "Epoch 954/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5183 - val_accuracy: 0.8929\n",
            "Epoch 955/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5198 - val_accuracy: 0.8929\n",
            "Epoch 956/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.8839\n",
            "Epoch 957/1000\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5339 - val_accuracy: 0.8929\n",
            "Epoch 958/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5329 - val_accuracy: 0.8929\n",
            "Epoch 959/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8929\n",
            "Epoch 960/1000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5590 - val_accuracy: 0.8750\n",
            "Epoch 961/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.9018\n",
            "Epoch 962/1000\n",
            "14/14 [==============================] - 5s 335ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5351 - val_accuracy: 0.8929\n",
            "Epoch 963/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.8750\n",
            "Epoch 964/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.8929\n",
            "Epoch 965/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.8929\n",
            "Epoch 966/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.8750\n",
            "Epoch 967/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.9018\n",
            "Epoch 968/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5531 - val_accuracy: 0.8750\n",
            "Epoch 969/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5107 - val_accuracy: 0.9018\n",
            "Epoch 970/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.8750\n",
            "Epoch 971/1000\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.8929\n",
            "Epoch 972/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5551 - val_accuracy: 0.8750\n",
            "Epoch 973/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.8929\n",
            "Epoch 974/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5656 - val_accuracy: 0.8750\n",
            "Epoch 975/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5376 - val_accuracy: 0.8929\n",
            "Epoch 976/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5496 - val_accuracy: 0.8750\n",
            "Epoch 977/1000\n",
            "14/14 [==============================] - 5s 337ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5446 - val_accuracy: 0.8750\n",
            "Epoch 978/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.8929\n",
            "Epoch 979/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5373 - val_accuracy: 0.8929\n",
            "Epoch 980/1000\n",
            "14/14 [==============================] - 4s 300ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5442 - val_accuracy: 0.8929\n",
            "Epoch 981/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.8839\n",
            "Epoch 982/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5285 - val_accuracy: 0.8929\n",
            "Epoch 983/1000\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 0.8750\n",
            "Epoch 984/1000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5300 - val_accuracy: 0.8929\n",
            "Epoch 985/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 0.9018\n",
            "Epoch 986/1000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5853 - val_accuracy: 0.8750\n",
            "Epoch 987/1000\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5264 - val_accuracy: 0.8929\n",
            "Epoch 988/1000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.8750\n",
            "Epoch 989/1000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5425 - val_accuracy: 0.8929\n",
            "Epoch 990/1000\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5555 - val_accuracy: 0.8750\n",
            "Epoch 991/1000\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.8929\n",
            "Epoch 992/1000\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5580 - val_accuracy: 0.8750\n",
            "Epoch 993/1000\n",
            "14/14 [==============================] - 4s 301ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5580 - val_accuracy: 0.8750\n",
            "Epoch 994/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5305 - val_accuracy: 0.8929\n",
            "Epoch 995/1000\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.8750\n",
            "Epoch 996/1000\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.8929\n",
            "Epoch 997/1000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.8929\n",
            "Epoch 998/1000\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5404 - val_accuracy: 0.8929\n",
            "Epoch 999/1000\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.8929\n",
            "Epoch 1000/1000\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.8750\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Save the model with the lowest validation loss\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', save_best_only=True, save_weights_only=False)\n",
        "\n",
        "history = model.fit(glaucoma_train_images, glaucoma_train_labels,\n",
        "                    epochs=5,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(glaucoma_test_images, glaucoma_test_labels),\n",
        "                    callbacks=[checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "LTbd_j74YQ7o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "12051d3d-b68d-43fc-f7b5-d04e4ef03891"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Assuming you have 'history' object from model training\n",
        "training_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "training_accuracy = history.history['accuracy']\n",
        "validation_accuracy = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Plotting loss\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, training_loss, 'bo-', label='Training Loss')\n",
        "plt.plot(epochs, validation_loss, 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, training_accuracy, 'bo-', label='Training Accuracy')\n",
        "plt.plot(epochs, validation_accuracy, 'ro-', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3zCqePdfMLC"
      },
      "outputs": [],
      "source": [
        "save_path = \"C:/AIProgram/saved_model.h5\"  # Specify your desired save path\n",
        "model.save(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_glaucoma_dataset_generator(dataset_path, image_size, batch_size=32):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',  # Assuming it's a binary classification task\n",
        "        shuffle=False  # Ensure that the order is preserved\n",
        "    )\n",
        "\n",
        "    # Retrieve the total number of samples\n",
        "    num_samples = generator.samples\n",
        "\n",
        "    return generator, num_samples\n",
        "\n",
        "# Example usage:\n",
        "your_dataset_path = r\"/content/drive/MyDrive/Dataset_Latihan\"\n",
        "your_image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "# Define the path to the test dataset\n",
        "test_dataset_path = os.path.join(your_dataset_path, 'test')\n",
        "\n",
        "# Create a generator for the test dataset\n",
        "test_generator, num_test_samples = load_glaucoma_dataset_generator(test_dataset_path, your_image_size, batch_size)\n",
        "\n",
        "# Define the path to your pre-trained model\n",
        "model_path = \"/content/drive/MyDrive/Dataset_Latihan/dummy_model.h5\"  # Change this to the path of your saved model\n",
        "\n",
        "# Load the pre-trained model\n",
        "loaded_model = load_model(model_path)\n",
        "\n",
        "# Initialize variables for confusion matrix\n",
        "all_true_labels = []\n",
        "all_predicted_labels = []\n",
        "\n",
        "# Threshold for classification\n",
        "threshold = 0.5\n",
        "\n",
        "# Calculate the total number of batches\n",
        "total_batches = num_test_samples // batch_size\n",
        "\n",
        "# Iterate over batches\n",
        "for i in range(total_batches + 1):  # +1 to include the last batch\n",
        "    batch_images, batch_labels = test_generator.next()\n",
        "\n",
        "    # Perform predictions on the batch\n",
        "    predictions = loaded_model.predict(batch_images)\n",
        "    predicted_labels = (predictions > threshold).astype(int).flatten()\n",
        "\n",
        "    # Append true and predicted labels for confusion matrix\n",
        "    all_true_labels.extend(batch_labels)\n",
        "    all_predicted_labels.extend(predicted_labels)\n",
        "\n",
        "    # Calculate loading and prediction process\n",
        "    process_percentage = (i + 1) / (total_batches + 1) * 100\n",
        "    print(f\"Processing: {process_percentage:.2f}%\")\n",
        "\n",
        "# Convert true and predicted labels to numpy arrays\n",
        "all_true_labels = np.array(all_true_labels)\n",
        "all_predicted_labels = np.array(all_predicted_labels)\n",
        "\n",
        "# Evaluate the model on the entire test set\n",
        "test_loss, test_accuracy = loaded_model.evaluate(test_generator)\n",
        "\n",
        "# Print test accuracy, test loss, confusion matrix, and classification report\n",
        "print(f\"\\nTest Accuracy: {test_accuracy}\")\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "class_report = classification_report(all_true_labels, all_predicted_labels)\n",
        "print(class_report)\n",
        "\n",
        "# Save the confusion matrix\n",
        "conf_matrix_save_path = \"/content/drive/MyDrive/confusion_matrix.npy\"\n",
        "np.save(conf_matrix_save_path, conf_matrix)\n",
        "print(f\"\\nConfusion Matrix saved at: {conf_matrix_save_path}\")"
      ],
      "metadata": {
        "id": "t0sW5LJA1j3C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}